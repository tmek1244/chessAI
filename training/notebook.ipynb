{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        self.optimizer = tf.optimizers.SGD(\n",
    "            learning_rate=0.001, momentum=0.8\n",
    "        )\n",
    "        self.loss = 'mean_absolute_error'\n",
    "        self.model = None\n",
    "        self.results = \"\"\n",
    "        # self.metrics= ['accuracy']\n",
    "\n",
    "        # self.load_or_create()\n",
    "        self.define()\n",
    "        # self.model.compile(optimizer=self.optimizer, loss=self.loss)\n",
    "        \n",
    "    def define(self):\n",
    "        dropout = 0.3\n",
    "        num_channels = 512\n",
    "        input_layer= tf.keras.Input(shape=(12, 8, 8))       \n",
    "        x_image = tf.keras.layers.Reshape((12, 8, 8, 1))(input_layer)                # batch_size  x board_x x board_y x 1\n",
    "        h_conv1 = tf.keras.layers.Activation('relu')(tf.keras.layers.BatchNormalization(axis=3)(tf.keras.layers.Conv2D(num_channels, 3, padding='same', use_bias=False)(x_image)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv2 = tf.keras.layers.Activation('relu')(tf.keras.layers.BatchNormalization(axis=3)(tf.keras.layers.Conv2D(num_channels, 3, padding='same', use_bias=False)(h_conv1)))         # batch_size  x board_x x board_y x num_channels\n",
    "        h_conv3 = tf.keras.layers.Activation('relu')(tf.keras.layers.BatchNormalization(axis=3)(tf.keras.layers.Conv2D(num_channels, 3, padding='valid', use_bias=False)(h_conv2)))        # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "        h_conv4 = tf.keras.layers.Activation('relu')(tf.keras.layers.BatchNormalization(axis=3)(tf.keras.layers.Conv2D(num_channels, 3, padding='valid', use_bias=False)(h_conv3)))        # batch_size  x (board_x-4) x (board_y-4) x num_channels\n",
    "        h_conv4_flat = tf.keras.layers.Flatten()(h_conv4)       \n",
    "        s_fc1 = tf.keras.layers.Dropout(dropout)(tf.keras.layers.Activation('relu')(tf.keras.layers.BatchNormalization(axis=1)(tf.keras.layers.Dense(1024, use_bias=False)(h_conv4_flat))))  # batch_size x 1024\n",
    "        s_fc2 = tf.keras.layers.Dropout(dropout)(tf.keras.layers.Activation('relu')(tf.keras.layers.BatchNormalization(axis=1)(tf.keras.layers.Dense(512, use_bias=False)(s_fc1))))          # batch_size x 1024\n",
    "        self.pi = tf.keras.layers.Dense(64*64, activation='softmax', name='pi')(s_fc2)   # batch_size x self.action_size\n",
    "        self.v = tf.keras.layers.Dense(1, activation='tanh', name='v')(s_fc2)                    # batch_size x 1\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=input_layer, outputs=[self.pi, self.v])\n",
    "        self.model.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=self.optimizer)\n",
    "\n",
    "    def load_or_create(self):\n",
    "        path = f\"models/{self.name}/architecutre.json\"\n",
    "        if not os.path.exists(path):\n",
    "            self.define()\n",
    "            return\n",
    "        \n",
    "        with open(f\"{path}\") as file:\n",
    "            config = json.load(file)\n",
    "            self.model = tf.keras.Model.from_config(config)\n",
    "            \n",
    "    \n",
    "    def save_architecutre(self):\n",
    "        path = f\"models/{self.name}\"\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        \n",
    "        with open(f\"{path}/architecutre.json\", 'w') as file:\n",
    "            json.dump(self.model.get_config(), file, indent=4)\n",
    "        \n",
    "        with open(f\"{path}/summary.txt\", 'w') as file:\n",
    "            def print_to_file(s):\n",
    "                print()\n",
    "            self.model.summary(print_fn=lambda x: print(x, file=file))\n",
    "    \n",
    "    def save_results(self):\n",
    "        path = f\"models/{self.name}\"\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        \n",
    "        with open(f\"{path}/results.txt\", 'w') as file:\n",
    "            file.write(self.results)\n",
    "    \n",
    "    def predict(self, board):\n",
    "        board = board[np.newaxis, :, :]\n",
    "        # run\n",
    "        pi, v = self.model.predict(board, verbose=False)\n",
    "\n",
    "        return pi[0], v[0]\n",
    "    \n",
    "    def train(self, examples):\n",
    "        input_boards, target_pis, target_vs = list(zip(*examples))\n",
    "        input_boards = np.asarray(input_boards)\n",
    "        target_pis = np.asarray(target_pis)\n",
    "        target_vs = np.asarray(target_vs)\n",
    "        self.model.fit(x = input_boards, y = [target_pis, target_vs], batch_size = 64, epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game import MCTS\n",
    "\n",
    "def policyIterSP(game):\n",
    "    nnet = NeuralNetwork()                                       # initialise random neural network\n",
    "    examples = []    \n",
    "    for i in range(10):\n",
    "        for e in range(10):\n",
    "            examples += executeEpisode(game, nnet)          # collect examples from this game\n",
    "        new_nnet = nnet.train(examples)                  \n",
    "        # frac_win = pit(new_nnet, nnet)                      # compare new net with previous net\n",
    "        # if frac_win > threshold: \n",
    "            # nnet = new_nnet                                 # replace with new net            \n",
    "    return nnet\n",
    "\n",
    "def assignRewards(examples, )\n",
    "\n",
    "def executeEpisode(game, nnet):\n",
    "    examples = []\n",
    "    s = game.startState()\n",
    "    mcts = MCTS()                                           # initialise search tree\n",
    "        \n",
    "    while True:\n",
    "        for _ in range(10):\n",
    "            mcts.search(s, game, nnet)\n",
    "        examples.append([s, mcts.pi(s), None])              # rewards can not be determined yet \n",
    "        a = np.random.choice(len(mcts.pi(s)), p=mcts.pi(s))    # sample action from improved policy\n",
    "        s = game.nextState(s,a)\n",
    "        if game.gameEnded(s):\n",
    "            examples = assignRewards(examples, game.gameReward(s)) \n",
    "            return examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f78c285c14cead02ab6c4268e58eb3f5481640740caa4851527120daa122cef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
