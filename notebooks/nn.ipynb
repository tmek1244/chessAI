{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_output(array):\n",
    "    return 1/(1 + 10**(array/400))\n",
    "    # return array/100\n",
    "\n",
    "def prepare(file, train_part=0.9):\n",
    "    df = pd.read_csv(file)\n",
    "    data, evaluations = df.iloc[:,:-1], df.iloc[:,-1:]\n",
    "    # print(data.shape)\n",
    "    # print(data.to_numpy())\n",
    "\n",
    "    # x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "    # x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "    # y_train = y_train.astype(\"float32\")\n",
    "    # y_test = y_test.astype(\"float32\")\n",
    "\n",
    "    # Reserve 10,000 samples for validation\n",
    "    x_train = data[:int(len(data)*train_part)].to_numpy().reshape((-1, 12, 8, 8))\n",
    "    y_train = prepare_output(evaluations[:int(len(data)*train_part)].to_numpy().flatten())\n",
    "    x_test = data[int(len(data)*train_part):].to_numpy().reshape((-1, 12, 8, 8))\n",
    "    y_test = prepare_output(evaluations[int(len(data)*train_part):].to_numpy().flatten())\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.optimizer = 'Adam'\n",
    "        self.loss = 'mean_absolute_error'\n",
    "        self.model = None\n",
    "        self.results = \"\"\n",
    "        # self.metrics= ['accuracy']\n",
    "\n",
    "        # self.load_or_create()\n",
    "        self.define()\n",
    "        self.model.compile(optimizer=self.optimizer, loss=self.loss)\n",
    "        \n",
    "    def define(self):\n",
    "        input_layer= tf.keras.Input(shape=(12, 8, 8))\n",
    "        x = tf.keras.layers.Conv2D(filters=64,kernel_size = 2,strides = (2,2))(input_layer)\n",
    "        x = tf.keras.layers.Conv2D(filters=128,kernel_size=2,strides = (2,2))(x)\n",
    "        x = tf.keras.layers.Conv2D(filters=256,kernel_size=2,strides = (2,2))(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        # x = tf.keras.layers.Dense(512,activation = 'relu')(input_layer)\n",
    "\n",
    "        x = tf.keras.layers.Dense(512,activation = 'relu')(x)\n",
    "        output = tf.keras.layers.Dense(1,activation = 'sigmoid')(x)\n",
    "\n",
    "        model = tf.keras.Model(name=self.name, inputs=input_layer,outputs=output)\n",
    "        self.model = model\n",
    "\n",
    "    def load_or_create(self):\n",
    "        path = f\"models/{self.name}/architecutre.json\"\n",
    "        if not os.path.exists(path):\n",
    "            self.define()\n",
    "            return\n",
    "        \n",
    "        with open(f\"{path}\") as file:\n",
    "            config = json.load(file)\n",
    "            self.model = tf.keras.Model.from_config(config)\n",
    "            \n",
    "    \n",
    "    def save_architecutre(self):\n",
    "        path = f\"models/{self.name}\"\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        \n",
    "        with open(f\"{path}/architecutre.json\", 'w') as file:\n",
    "            json.dump(self.model.get_config(), file, indent=4)\n",
    "        \n",
    "        with open(f\"{path}/summary.txt\", 'w') as file:\n",
    "            def print_to_file(s):\n",
    "                print()\n",
    "            self.model.summary(print_fn=lambda x: print(x, file=file))\n",
    "    \n",
    "    def save_results(self):\n",
    "        path = f\"models/{self.name}\"\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        \n",
    "        with open(f\"{path}/results.txt\", 'w') as file:\n",
    "            file.write(self.results)\n",
    "\n",
    "\n",
    "nn = NeuralNetwork(name=\"conv_3_512\")\n",
    "# nn.save_architecutre()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_3_512\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 12, 8, 8)]        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 6, 4, 64)          2112      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 3, 2, 128)         32896     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 1, 1, 256)         131328    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 298,433\n",
      "Trainable params: 298,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30663, 12, 8, 8) (0, 12, 8, 8)\n",
      "1.0\n",
      "Epoch 1/25\n",
      "671/671 [==============================] - 4s 5ms/step - loss: 0.1539 - val_loss: 0.1759\n",
      "Epoch 2/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1517 - val_loss: 0.1803\n",
      "Epoch 3/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1516 - val_loss: 0.1655\n",
      "Epoch 4/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1510 - val_loss: 0.1791\n",
      "Epoch 5/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1502 - val_loss: 0.1635\n",
      "Epoch 6/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1502 - val_loss: 0.1824\n",
      "Epoch 7/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1481 - val_loss: 0.1713\n",
      "Epoch 8/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1481 - val_loss: 0.1734\n",
      "Epoch 9/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1487 - val_loss: 0.1856\n",
      "Epoch 10/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1485 - val_loss: 0.1664\n",
      "Epoch 11/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1470 - val_loss: 0.1718\n",
      "Epoch 12/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1470 - val_loss: 0.1725\n",
      "Epoch 13/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1450 - val_loss: 0.1843\n",
      "Epoch 14/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1452 - val_loss: 0.1754\n",
      "Epoch 15/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1452 - val_loss: 0.1733\n",
      "Epoch 16/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1448 - val_loss: 0.1750\n",
      "Epoch 17/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1442 - val_loss: 0.1851\n",
      "Epoch 18/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1449 - val_loss: 0.1752\n",
      "Epoch 19/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1442 - val_loss: 0.1745\n",
      "Epoch 20/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1434 - val_loss: 0.1786\n",
      "Epoch 21/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1432 - val_loss: 0.1697\n",
      "Epoch 22/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1420 - val_loss: 0.1900\n",
      "Epoch 23/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1427 - val_loss: 0.1718\n",
      "Epoch 24/25\n",
      "671/671 [==============================] - 3s 5ms/step - loss: 0.1426 - val_loss: 0.1712\n",
      "Epoch 25/25\n",
      "671/671 [==============================] - 4s 5ms/step - loss: 0.1423 - val_loss: 0.1710\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = prepare('start_15_depth_10_moves_3.csv', 1)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(np.max(y_train))\n",
    "\n",
    "history = nn.model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=25,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_split=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.2726\n",
      "test loss: 0.2726458013057709\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = prepare('data1.csv', train_part=0)\n",
    "\n",
    "print(\"Evaluate on test data\")\n",
    "results = nn.model.evaluate(x_test, y_test, batch_size=32)\n",
    "print(\"test loss:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.1382 - val_loss: 0.4597\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.1010 - val_loss: 0.4734\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.1008 - val_loss: 0.4751\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.1000 - val_loss: 0.4714\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.1001 - val_loss: 0.4773\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.1007 - val_loss: 0.4653\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.1000 - val_loss: 0.4814\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.1000 - val_loss: 0.4767\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1000 - val_loss: 0.4795\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.1002 - val_loss: 0.4689\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.1000 - val_loss: 0.4742\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 0.0999 - val_loss: 0.4776\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.0999 - val_loss: 0.4712\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.0999 - val_loss: 0.4686\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.1002 - val_loss: 0.4641\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.1000 - val_loss: 0.4706\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.0999 - val_loss: 0.4729\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.0999 - val_loss: 0.4692\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.0999 - val_loss: 0.4691\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.1000 - val_loss: 0.4776\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.0999 - val_loss: 0.4727\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 0.1001 - val_loss: 0.4736\n",
      "Epoch 23/30\n",
      "32/57 [===============>..............] - ETA: 0s - loss: 0.1014"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_train, y_train, x_test, y_test \u001b[39m=\u001b[39m prepare(\u001b[39m'\u001b[39m\u001b[39mdata1.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     x_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     y_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# We pass some validation for\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# monitoring validation loss and metrics\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# at the end of each epoch\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     validation_split \u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tmek1244/InternalProjects/chessAI/notebooks/nn.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n",
      "File \u001b[0;32m~/InternalProjects/chessAI/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/InternalProjects/chessAI/venv/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/InternalProjects/chessAI/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/InternalProjects/chessAI/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/InternalProjects/chessAI/venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/InternalProjects/chessAI/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/InternalProjects/chessAI/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/InternalProjects/chessAI/venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/InternalProjects/chessAI/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = prepare('data1.csv')\n",
    "\n",
    "history = nn.model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0898 - val_loss: 0.0626\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0823 - val_loss: 0.0637\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0818 - val_loss: 0.0593\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0816 - val_loss: 0.0590\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0818 - val_loss: 0.0594\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0597\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0819 - val_loss: 0.0593\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0594\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0818 - val_loss: 0.0591\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0816 - val_loss: 0.0600\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0816 - val_loss: 0.0599\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0591\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0599\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0816 - val_loss: 0.0597\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0817 - val_loss: 0.0592\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 0.0817 - val_loss: 0.0599\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0817 - val_loss: 0.0589\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0599\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0816 - val_loss: 0.0593\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0817 - val_loss: 0.0594\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0816 - val_loss: 0.0593\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0600\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0817 - val_loss: 0.0595\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0597\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0597\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0817 - val_loss: 0.0599\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0817 - val_loss: 0.0594\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0816 - val_loss: 0.0594\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0817 - val_loss: 0.0593\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 0.0816 - val_loss: 0.0591\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0816 - val_loss: 0.0592\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 0.0817 - val_loss: 0.0594\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.0816 - val_loss: 0.0600\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0599\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.0817 - val_loss: 0.0594\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0593\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0817 - val_loss: 0.0594\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0817 - val_loss: 0.0598\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0592\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 0.0817 - val_loss: 0.0590\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0815 - val_loss: 0.0604\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0594\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0816 - val_loss: 0.0593\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0816 - val_loss: 0.0600\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 0.0816 - val_loss: 0.0593\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0600\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0817 - val_loss: 0.0589\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0601\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0816 - val_loss: 0.0597\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 0.0816 - val_loss: 0.0592\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0602\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0594\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0817 - val_loss: 0.0601\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0817 - val_loss: 0.0593\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0817 - val_loss: 0.0598\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0817 - val_loss: 0.0591\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 0.0816 - val_loss: 0.0594\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 0.0816 - val_loss: 0.0596\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0595\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 0.0816 - val_loss: 0.0598\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0816 - val_loss: 0.0594\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0600\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0817 - val_loss: 0.0594\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0594\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.0816 - val_loss: 0.0596\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = prepare('data2.csv')\n",
    "\n",
    "history = nn.model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.2487 - val_loss: 0.2325\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1555 - val_loss: 0.2203\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1554 - val_loss: 0.2254\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1557 - val_loss: 0.2231\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1552 - val_loss: 0.2150\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1560 - val_loss: 0.2178\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1554 - val_loss: 0.2275\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1561 - val_loss: 0.2204\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1559 - val_loss: 0.2251\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1552 - val_loss: 0.2120\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1552 - val_loss: 0.2243\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1567 - val_loss: 0.2170\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1554 - val_loss: 0.2188\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1556 - val_loss: 0.2288\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1555 - val_loss: 0.2114\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1552 - val_loss: 0.2182\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1553 - val_loss: 0.2165\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1553 - val_loss: 0.2183\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1553 - val_loss: 0.2217\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1554 - val_loss: 0.2364\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1562 - val_loss: 0.2165\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1555 - val_loss: 0.2161\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1552 - val_loss: 0.2160\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1552 - val_loss: 0.2297\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1552 - val_loss: 0.2235\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1554 - val_loss: 0.2269\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1552 - val_loss: 0.2134\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1552 - val_loss: 0.2129\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1553 - val_loss: 0.2215\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1552 - val_loss: 0.2204\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1554 - val_loss: 0.2237\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.1551 - val_loss: 0.2254\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1553 - val_loss: 0.2132\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1556 - val_loss: 0.2187\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1560 - val_loss: 0.2245\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1553 - val_loss: 0.2224\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1552 - val_loss: 0.2282\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1555 - val_loss: 0.2262\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1556 - val_loss: 0.2310\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1554 - val_loss: 0.2108\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.1563 - val_loss: 0.2249\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.1554 - val_loss: 0.2238\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1554 - val_loss: 0.2229\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1555 - val_loss: 0.2243\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1552 - val_loss: 0.2251\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1555 - val_loss: 0.2153\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1555 - val_loss: 0.2200\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1558 - val_loss: 0.2266\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1553 - val_loss: 0.2204\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1555 - val_loss: 0.2157\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1552 - val_loss: 0.2303\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1557 - val_loss: 0.2248\n",
      "Epoch 53/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1551 - val_loss: 0.2129\n",
      "Epoch 54/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1554 - val_loss: 0.2213\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1556 - val_loss: 0.2198\n",
      "Epoch 56/100\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1552 - val_loss: 0.2281\n",
      "Epoch 57/100\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.1559 - val_loss: 0.2223\n",
      "Epoch 58/100\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1553 - val_loss: 0.2220\n",
      "Epoch 59/100\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1552 - val_loss: 0.2178\n",
      "Epoch 60/100\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1554 - val_loss: 0.2222\n",
      "Epoch 61/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1553 - val_loss: 0.2245\n",
      "Epoch 62/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1553 - val_loss: 0.2235\n",
      "Epoch 63/100\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.1553 - val_loss: 0.2256\n",
      "Epoch 64/100\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1554 - val_loss: 0.2262\n",
      "Epoch 65/100\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1552 - val_loss: 0.2201\n",
      "Epoch 66/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1553 - val_loss: 0.2202\n",
      "Epoch 67/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1553 - val_loss: 0.2282\n",
      "Epoch 68/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1556 - val_loss: 0.2169\n",
      "Epoch 69/100\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.1556 - val_loss: 0.2259\n",
      "Epoch 70/100\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1555 - val_loss: 0.2272\n",
      "Epoch 71/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1552 - val_loss: 0.2240\n",
      "Epoch 72/100\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1553 - val_loss: 0.2215\n",
      "Epoch 73/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1553 - val_loss: 0.2173\n",
      "Epoch 74/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1555 - val_loss: 0.2180\n",
      "Epoch 75/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1553 - val_loss: 0.2234\n",
      "Epoch 76/100\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1552 - val_loss: 0.2185\n",
      "Epoch 77/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1555 - val_loss: 0.2300\n",
      "Epoch 78/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1553 - val_loss: 0.2230\n",
      "Epoch 79/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1553 - val_loss: 0.2170\n",
      "Epoch 80/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1554 - val_loss: 0.2147\n",
      "Epoch 81/100\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1557 - val_loss: 0.2258\n",
      "Epoch 82/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1552 - val_loss: 0.2190\n",
      "Epoch 83/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1554 - val_loss: 0.2279\n",
      "Epoch 84/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1551 - val_loss: 0.2181\n",
      "Epoch 85/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1551 - val_loss: 0.2113\n",
      "Epoch 86/100\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1554 - val_loss: 0.2175\n",
      "Epoch 87/100\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.1551 - val_loss: 0.2139\n",
      "Epoch 88/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1554 - val_loss: 0.2138\n",
      "Epoch 89/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1551 - val_loss: 0.2185\n",
      "Epoch 90/100\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.1553 - val_loss: 0.2205\n",
      "Epoch 91/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1551 - val_loss: 0.2179\n",
      "Epoch 92/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1555 - val_loss: 0.2186\n",
      "Epoch 93/100\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.1554 - val_loss: 0.2147\n",
      "Epoch 94/100\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.1553 - val_loss: 0.2198\n",
      "Epoch 95/100\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 0.1553 - val_loss: 0.2129\n",
      "Epoch 96/100\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 0.1551 - val_loss: 0.2109\n",
      "Epoch 97/100\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.1552 - val_loss: 0.2226\n",
      "Epoch 98/100\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 0.1552 - val_loss: 0.2274\n",
      "Epoch 99/100\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.1555 - val_loss: 0.2193\n",
      "Epoch 100/100\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.1552 - val_loss: 0.2293\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = prepare('start_15_depth_10_moves_3.csv')\n",
    "\n",
    "history = nn.model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0765\n",
      "test loss, test acc: 0.07646416872739792\n",
      "Generate predictions for 3 samples\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "predictions shape: (3, 12, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = nn.model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = nn.model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f78c285c14cead02ab6c4268e58eb3f5481640740caa4851527120daa122cef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
